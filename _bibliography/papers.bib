@article{YANG2024100601,
title = {Applications of cluster-based transfer learning in image and localization tasks},
journal = {Machine Learning with Applications},
volume = {18},
pages = {100601},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100601},
url = {https://www.sciencedirect.com/science/article/pii/S266682702400077X},
author = {Liuyi Yang and Patrick Finnerty and Chikara Ohta},
keywords = {Semi-supervised transfer learning, Fine-tune, Localization, Image recognition},
abstract = {Transfer learning can address the issue of insufficient labels in machine learning. Using knowledge in a labeled domain (source domain) can assist in acquiring and learning knowledge in a domain (target domain) that lacks some or all labels. In this paper, we propose a new cluster-based semi-supervised transfer learning (CBSSTL) under a new assumption that samples in the target domain are unlabeled but contain cluster information. Furthermore, we propose a new transfer learning framework and a method for fine-tuning parameters. We tested and compared the proposed method with other unsupervised and semi-supervised transfer learning methods on well-known image datasets. The experimental results demonstrate the effectiveness of the proposed method. Additionally, we created a localization dataset for transfer learning. Finally, we tested and analyzed the proposed method on this dataset. Its particularly challenging nature makes it difficult for our method to work effectively.}
}

@Article{su17062592,
AUTHOR = {Yang, Liuyi and Chen, Sinan and Li, Jialong},
TITLE = {Enhancing Sustainable AI-Driven Language Learning: Location-Based Vocabulary Training for Learners of Japanese},
JOURNAL = {Sustainability},
VOLUME = {17},
YEAR = {2025},
NUMBER = {6},
ARTICLE-NUMBER = {2592},
URL = {https://www.mdpi.com/2071-1050/17/6/2592},
ISSN = {2071-1050},
ABSTRACT = {With the rapid advancement of mobile technology, e-learning has expanded significantly, making language learning more accessible than ever. At the same time, the rise of artificial intelligence (AI) technologies has opened new avenues for adaptive and personalized e-learning experiences. However, traditional e-learning methods remain limited by their reliance on static, predefined materials, which restricts equitable access to learning resources and fails to fully support lifelong learning. To address this limitation, this study proposes a location-based AI-driven e-learning system that dynamically generates language learning materials tailored to real-world contexts by integrating location-awareness technology with AI. This approach enables learners to acquire language skills that are directly applicable to their physical surroundings, thereby enhancing engagement, comprehension, and retention. Both objective evaluation and user surveys confirm the reliability and effectiveness of AI-generated language learning materials. Specifically, user surveys indicate that the generated content achieves a content relevance score of 8.4/10, an accuracy score of 8.8/10, a motivation score of 7.9/10, and a learning efficiency score of 7.8/10. Our method can reduce reliance on predefined content, allowing learners to access location-relevant learning resources anytime and anywhere, thereby improving accessibility and fostering lifelong learning in the context of sustainable education.},
DOI = {10.3390/su17062592}
}

@Article{app15073937,
AUTHOR = {Xie, Yangmei and Yang, Liuyi and Zhang, Miao and Chen, Sinan and Li, Jialong},
TITLE = {A Review of Multimodal Interaction in Remote Education: Technologies, Applications, and Challenges},
JOURNAL = {Applied Sciences},
VOLUME = {15},
YEAR = {2025},
NUMBER = {7},
ARTICLE-NUMBER = {3937},
URL = {https://www.mdpi.com/2076-3417/15/7/3937},
ISSN = {2076-3417},
ABSTRACT = {Multimodal interaction technology has become a key aspect of remote education by enriching student engagement and learning results as it utilizes the speech, gesture, and visual feedback as various sensory channels. This publication reflects on the latest breakthroughs in multimodal interaction and its usage in remote learning environments, including a multi-layered discussion that addresses various levels of learning and understanding. It showcases the main technologies, such as speech recognition, computer vision, and haptic feedback, that enable the visitors and learning portals to exchange data fluidly. In addition, we investigate the function of multimodal learning analytics in order to measure the cognitive and emotional states of students, targeting personalized feedback and refining instructional strategies. Though multimodal communication may bring a historical improvement to the mode of online education, the platform still faces many issues, such as media synchronization, higher computational demand, physical adaptability, and privacy concerns. These problems demand further research in the fields of algorithm optimization, access to technology guidance, and the ethical use of big data. This paper presents a systematic review of the application of multimodal interaction in remote education. Through the analysis of 25 selected research papers, this review explores key technologies, applications, and challenges in the field. By synthesizing existing findings, this study highlights the role of multimodal learning analytics, speech recognition, gesture-based interaction, and haptic feedback in enhancing remote learning.},
DOI = {10.3390/app15073937}
}

@Article{app15073807,
AUTHOR = {Chen, Sinan and Yang, Liuyi and Zhang, Yue and Zhang, Miao and Xie, Yangmei and Zhu, Zhiyi and Li, Jialong},
TITLE = {Digital Human Technology in E-Learning: Custom Content Solutions},
JOURNAL = {Applied Sciences},
VOLUME = {15},
YEAR = {2025},
NUMBER = {7},
ARTICLE-NUMBER = {3807},
URL = {https://www.mdpi.com/2076-3417/15/7/3807},
ISSN = {2076-3417},
ABSTRACT = {With advances in digital transformation (DX) in education and digital technologies becoming more deeply integrated into educational settings, global demand for video-based learning materials continues to rise, resulting in substantial effort being required from teachers to create e-learning videos. Furthermore, while many existing services offer visual content, they primarily rely on templates, making it challenging to design custom content that addresses specific needs. In this study, we develop a web service that facilitates e-learning video creation through integrated artificial intelligence (AI) and digital human technology. This service enhances educational content by integrating digital human characters and voice synthesis technologies, aiming to create comprehensive e-learning videos by incorporating visual motion and synchronized audio into educational content. In addition, this service also aims to enable the creation of engaging content through advanced visuals and animations, effectively maintaining learner interest.},
DOI = {10.3390/app15073807}
}

@article{Liuyi Yang20212021XBL0075,
  title={Indoor localization based on CSI in dynamic environments through domain adaptation},
  author={Liuyi Yang and Tomio Kamada and Chikara Ohta},
  journal={IEICE Communications Express},
  volume={10},
  number={8},
  pages={564-569},
  year={2021},
  doi={10.1587/comex.2021XBL0075}
}

